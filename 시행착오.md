# 베이스 모델 2025-02-20

- 모델: RandomForest 기본값 (파라미터 조정 X)

- 범주형 데이터 인코딩

        원핫 인코딩: '주거 형태', 대출 목적,
        라벨 인코딩: '현재 직장 근속 연수', '대출 상환 기간'

- features = ['연간 소득', '현재 직장 근속 연수', '체납 세금 압류 횟수', '개설된 신용계좌 수', '신용 거래 연수',
    '최대 신용한도', '신용 문제 발생 횟수', '마지막 연체 이후 경과 개월 수', '개인 파산 횟수', '대출 상환 기간',
    '현재 대출 잔액', '현재 미상환 신용액', '월 상환 부채액', '신용 점수', '주거 형태_월세',
    '주거 형태_자가', '주거 형태_주택 담보 대출 (거주 중)', '주거 형태_주택 담보 대출 (비거주 중)',
    '대출 목적_결혼 자금', '대출 목적_고액 구매', '대출 목적_교육비', '대출 목적_기타', '대출 목적_부채 통합',
    '대출 목적_사업 대출', '대출 목적_소규모 사업 자금', '대출 목적_여행 자금', '대출 목적_의료비',
    '대출 목적_이사 비용', '대출 목적_자동차 구매', '대출 목적_주택 개보수', '대출 목적_주택 구매',
    '대출 목적_휴가 비용'
]

- **점수: 0.5651**

# 2025-02-21

**점수 0.5527**

2025-02-20 모델이 Class 1으로 예측한 것 중 대부분이 실제 Class 1이 맞지만, 실제 Class 1 중 많은 부분을 놓치고 있다.

즉, 모델이 Class 1으로 예측한 값은 비교적 신뢰할 수 있으나, Class 1 자체를 충분히 잘 탐지하지 못하고 있다는 의미

2025-02-20 모델이 정밀도와 재현율이 현저히 차이나서 오버피팅이 되었다고 생각함.

feature importance가 낮은 피쳐들을 제거 후 학습하면 오버피팅 되지 않을 것이라는 가설을 세움

오히려 점수가 떨어짐

features = ['연간 소득', '개설된 신용계좌 수', '신용 거래 연수',
    '최대 신용한도', '마지막 연체 이후 경과 개월 수',
    '현재 대출 잔액', '현재 미상환 신용액', '월 상환 부채액', '신용 점수'
]

# 2025-02-23
**점수 0.5682**

수치형 데이터인 체납 세금 압류 횟수, 신용 문제 발생 횟수, 개인 파산 횟수를 범주형으로 변경

대출 목적: 부채 통합이면 1 아니면 0으로 수정

주거 형태: 주택 담보 대출 (비거주 중) 피쳐에서 제거

features = ['연간 소득', '현재 직장 근속 연수', '체납 세금 압류 횟수', '개설된 신용계좌 수', '신용 거래 연수',
    '최대 신용한도', '신용 문제 발생 횟수', '마지막 연체 이후 경과 개월 수', '개인 파산 횟수', '대출 목적',
    '대출 상환 기간', '현재 대출 잔액', '현재 미상환 신용액', '월 상환 부채액', '신용 점수',
    '주거 형태_월세', '주거 형태_자가', '주거 형태_주택 담보 대출 (거주 중)',
]

1로 예측할 때 recall 0.31 -> 0.36으로 0.05 개선됨

# 2025-03-03
**점수 0.5746**

2025-02-23에서 수치형 데이터 yeo-johnson transform

# 딥러닝으로 학습해보자
