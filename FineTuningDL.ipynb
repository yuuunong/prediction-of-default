{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "train_features_path = Path(data_path) / 'train_features.csv'\n",
    "train_target_path = Path(data_path) / 'train_target.csv'\n",
    "test_path = Path(data_path) / 'test_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_features = pd.read_csv(train_features_path)\n",
    "train_target = pd.read_csv(train_target_path)\n",
    "test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   연간 소득                  10000 non-null  float64\n",
      " 1   현재 직장 근속 연수            10000 non-null  int64  \n",
      " 2   체납 세금 압류 횟수            10000 non-null  int64  \n",
      " 3   개설된 신용계좌 수             10000 non-null  float64\n",
      " 4   신용 거래 연수               10000 non-null  float64\n",
      " 5   최대 신용한도                10000 non-null  float64\n",
      " 6   신용 문제 발생 횟수            10000 non-null  int64  \n",
      " 7   마지막 연체 이후 경과 개월 수      10000 non-null  float64\n",
      " 8   개인 파산 횟수               10000 non-null  int64  \n",
      " 9   대출 목적                  10000 non-null  int64  \n",
      " 10  대출 상환 기간               10000 non-null  int64  \n",
      " 11  현재 대출 잔액               10000 non-null  float64\n",
      " 12  현재 미상환 신용액             10000 non-null  float64\n",
      " 13  월 상환 부채액               10000 non-null  float64\n",
      " 14  신용 점수                  10000 non-null  float64\n",
      " 15  주거 형태_월세               10000 non-null  bool   \n",
      " 16  주거 형태_자가               10000 non-null  bool   \n",
      " 17  주거 형태_주택 담보 대출 (거주 중)  10000 non-null  bool   \n",
      "dtypes: bool(3), float64(9), int64(6)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "train_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   채무 불이행 여부  10000 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 78.3 KB\n"
     ]
    }
   ],
   "source": [
    "train_target.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features, train_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8000 entries, 9254 to 7270\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   연간 소득                  8000 non-null   float64\n",
      " 1   현재 직장 근속 연수            8000 non-null   float64\n",
      " 2   체납 세금 압류 횟수            8000 non-null   float64\n",
      " 3   개설된 신용계좌 수             8000 non-null   float64\n",
      " 4   신용 거래 연수               8000 non-null   float64\n",
      " 5   최대 신용한도                8000 non-null   float64\n",
      " 6   신용 문제 발생 횟수            8000 non-null   float64\n",
      " 7   마지막 연체 이후 경과 개월 수      8000 non-null   float64\n",
      " 8   개인 파산 횟수               8000 non-null   float64\n",
      " 9   대출 목적                  8000 non-null   float64\n",
      " 10  대출 상환 기간               8000 non-null   float64\n",
      " 11  현재 대출 잔액               8000 non-null   float64\n",
      " 12  현재 미상환 신용액             8000 non-null   float64\n",
      " 13  월 상환 부채액               8000 non-null   float64\n",
      " 14  신용 점수                  8000 non-null   float64\n",
      " 15  주거 형태_월세               8000 non-null   float64\n",
      " 16  주거 형태_자가               8000 non-null   float64\n",
      " 17  주거 형태_주택 담보 대출 (거주 중)  8000 non-null   float64\n",
      "dtypes: float64(18)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train.astype(np.float64).info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45557939, 10.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.21117022, 10.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.44183187,  2.        ,  0.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.33806261,  2.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.12685507,  1.        ,  0.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.67944341,  9.        ,  1.        , ...,  0.        ,\n",
       "         0.        ,  1.        ]], shape=(8000, 18))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.astype(np.float64).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45557939, 10.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.21117022, 10.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.44183187,  2.        ,  0.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.33806261,  2.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.12685507,  1.        ,  0.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.67944341,  9.        ,  1.        , ...,  0.        ,\n",
       "         0.        ,  1.        ]], shape=(8000, 18))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train.astype(np.float64).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\ML\\prediction-of-default\\.venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n",
      "c:\\dev\\ML\\prediction-of-default\\.venv\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.65752 |  0:00:00s\n",
      "epoch 1  | loss: 0.60676 |  0:00:01s\n",
      "epoch 2  | loss: 0.59597 |  0:00:02s\n",
      "epoch 3  | loss: 0.58704 |  0:00:03s\n",
      "epoch 4  | loss: 0.57849 |  0:00:03s\n",
      "epoch 5  | loss: 0.57903 |  0:00:04s\n",
      "epoch 6  | loss: 0.57835 |  0:00:05s\n",
      "epoch 7  | loss: 0.571   |  0:00:06s\n",
      "epoch 8  | loss: 0.56891 |  0:00:06s\n",
      "epoch 9  | loss: 0.56853 |  0:00:07s\n",
      "epoch 10 | loss: 0.56468 |  0:00:08s\n",
      "epoch 11 | loss: 0.56149 |  0:00:09s\n",
      "epoch 12 | loss: 0.56321 |  0:00:09s\n",
      "epoch 13 | loss: 0.55968 |  0:00:10s\n",
      "epoch 14 | loss: 0.55937 |  0:00:11s\n",
      "epoch 15 | loss: 0.55925 |  0:00:12s\n",
      "epoch 16 | loss: 0.56009 |  0:00:12s\n",
      "epoch 17 | loss: 0.56374 |  0:00:13s\n",
      "epoch 18 | loss: 0.56493 |  0:00:14s\n",
      "epoch 19 | loss: 0.55802 |  0:00:15s\n",
      "epoch 20 | loss: 0.55555 |  0:00:15s\n",
      "epoch 21 | loss: 0.55283 |  0:00:16s\n",
      "epoch 22 | loss: 0.55281 |  0:00:17s\n",
      "epoch 23 | loss: 0.55603 |  0:00:18s\n",
      "epoch 24 | loss: 0.56091 |  0:00:18s\n",
      "epoch 25 | loss: 0.55604 |  0:00:19s\n",
      "epoch 26 | loss: 0.55254 |  0:00:20s\n",
      "epoch 27 | loss: 0.55454 |  0:00:21s\n",
      "epoch 28 | loss: 0.55309 |  0:00:22s\n",
      "epoch 29 | loss: 0.54918 |  0:00:22s\n",
      "epoch 30 | loss: 0.54948 |  0:00:23s\n",
      "epoch 31 | loss: 0.54707 |  0:00:25s\n",
      "epoch 32 | loss: 0.54707 |  0:00:30s\n",
      "epoch 33 | loss: 0.55172 |  0:00:34s\n",
      "epoch 34 | loss: 0.55197 |  0:00:38s\n",
      "epoch 35 | loss: 0.5495  |  0:00:44s\n",
      "epoch 36 | loss: 0.54631 |  0:00:48s\n",
      "epoch 37 | loss: 0.5426  |  0:00:52s\n",
      "epoch 38 | loss: 0.54358 |  0:00:56s\n",
      "epoch 39 | loss: 0.5496  |  0:01:01s\n",
      "epoch 40 | loss: 0.54368 |  0:01:05s\n",
      "epoch 41 | loss: 0.54353 |  0:01:09s\n",
      "epoch 42 | loss: 0.54036 |  0:01:13s\n",
      "epoch 43 | loss: 0.5434  |  0:01:16s\n",
      "epoch 44 | loss: 0.54184 |  0:01:16s\n",
      "epoch 45 | loss: 0.53988 |  0:01:17s\n",
      "epoch 46 | loss: 0.54    |  0:01:18s\n",
      "epoch 47 | loss: 0.53791 |  0:01:19s\n",
      "epoch 48 | loss: 0.54489 |  0:01:20s\n",
      "epoch 49 | loss: 0.54185 |  0:01:21s\n",
      "epoch 50 | loss: 0.54777 |  0:01:21s\n",
      "epoch 51 | loss: 0.54109 |  0:01:22s\n",
      "epoch 52 | loss: 0.53756 |  0:01:23s\n",
      "epoch 53 | loss: 0.53822 |  0:01:24s\n",
      "epoch 54 | loss: 0.54028 |  0:01:25s\n",
      "epoch 55 | loss: 0.54704 |  0:01:26s\n",
      "epoch 56 | loss: 0.54672 |  0:01:27s\n",
      "epoch 57 | loss: 0.55312 |  0:01:28s\n",
      "epoch 58 | loss: 0.5512  |  0:01:31s\n",
      "epoch 59 | loss: 0.54707 |  0:01:34s\n",
      "epoch 60 | loss: 0.54109 |  0:01:37s\n",
      "epoch 61 | loss: 0.53467 |  0:01:41s\n",
      "epoch 62 | loss: 0.53604 |  0:01:44s\n",
      "epoch 63 | loss: 0.53942 |  0:01:48s\n",
      "epoch 64 | loss: 0.5363  |  0:01:51s\n",
      "epoch 65 | loss: 0.53402 |  0:01:55s\n",
      "epoch 66 | loss: 0.53954 |  0:01:58s\n",
      "epoch 67 | loss: 0.53865 |  0:02:01s\n",
      "epoch 68 | loss: 0.54629 |  0:02:05s\n",
      "epoch 69 | loss: 0.53941 |  0:02:08s\n",
      "epoch 70 | loss: 0.53621 |  0:02:11s\n",
      "epoch 71 | loss: 0.53456 |  0:02:15s\n",
      "epoch 72 | loss: 0.53746 |  0:02:18s\n",
      "epoch 73 | loss: 0.54008 |  0:02:22s\n",
      "epoch 74 | loss: 0.53106 |  0:02:25s\n",
      "epoch 75 | loss: 0.52814 |  0:02:29s\n",
      "epoch 76 | loss: 0.53009 |  0:02:32s\n",
      "epoch 77 | loss: 0.53232 |  0:02:35s\n",
      "epoch 78 | loss: 0.53567 |  0:02:39s\n",
      "epoch 79 | loss: 0.53727 |  0:02:42s\n",
      "epoch 80 | loss: 0.53188 |  0:02:46s\n",
      "epoch 81 | loss: 0.52713 |  0:02:49s\n",
      "epoch 82 | loss: 0.53054 |  0:02:53s\n",
      "epoch 83 | loss: 0.52841 |  0:02:56s\n",
      "epoch 84 | loss: 0.52792 |  0:02:59s\n",
      "epoch 85 | loss: 0.52798 |  0:03:03s\n",
      "epoch 86 | loss: 0.52306 |  0:03:06s\n",
      "epoch 87 | loss: 0.52103 |  0:03:10s\n",
      "epoch 88 | loss: 0.51984 |  0:03:13s\n",
      "epoch 89 | loss: 0.51939 |  0:03:17s\n",
      "epoch 90 | loss: 0.52593 |  0:03:20s\n",
      "epoch 91 | loss: 0.52327 |  0:03:23s\n",
      "epoch 92 | loss: 0.52829 |  0:03:27s\n",
      "epoch 93 | loss: 0.53122 |  0:03:31s\n",
      "epoch 94 | loss: 0.53898 |  0:03:34s\n",
      "epoch 95 | loss: 0.55227 |  0:03:37s\n",
      "epoch 96 | loss: 0.55062 |  0:03:41s\n",
      "epoch 97 | loss: 0.54512 |  0:03:44s\n",
      "epoch 98 | loss: 0.53788 |  0:03:47s\n",
      "epoch 99 | loss: 0.53594 |  0:03:51s\n",
      "epoch 100| loss: 0.5347  |  0:03:54s\n",
      "epoch 101| loss: 0.52904 |  0:03:58s\n",
      "epoch 102| loss: 0.52573 |  0:04:01s\n",
      "epoch 103| loss: 0.52334 |  0:04:05s\n",
      "epoch 104| loss: 0.52074 |  0:04:08s\n",
      "epoch 105| loss: 0.51934 |  0:04:12s\n",
      "epoch 106| loss: 0.51492 |  0:04:16s\n",
      "epoch 107| loss: 0.51371 |  0:04:18s\n",
      "epoch 108| loss: 0.51591 |  0:04:19s\n",
      "epoch 109| loss: 0.52056 |  0:04:19s\n",
      "epoch 110| loss: 0.51738 |  0:04:20s\n",
      "epoch 111| loss: 0.51074 |  0:04:21s\n",
      "epoch 112| loss: 0.51378 |  0:04:22s\n",
      "epoch 113| loss: 0.51569 |  0:04:22s\n",
      "epoch 114| loss: 0.50989 |  0:04:23s\n",
      "epoch 115| loss: 0.50777 |  0:04:24s\n",
      "epoch 116| loss: 0.50922 |  0:04:25s\n",
      "epoch 117| loss: 0.50598 |  0:04:25s\n",
      "epoch 118| loss: 0.51016 |  0:04:26s\n",
      "epoch 119| loss: 0.51149 |  0:04:27s\n",
      "epoch 120| loss: 0.50514 |  0:04:28s\n",
      "epoch 121| loss: 0.50048 |  0:04:28s\n",
      "epoch 122| loss: 0.4975  |  0:04:29s\n",
      "epoch 123| loss: 0.51147 |  0:04:30s\n",
      "epoch 124| loss: 0.50054 |  0:04:31s\n",
      "epoch 125| loss: 0.50253 |  0:04:31s\n",
      "epoch 126| loss: 0.50252 |  0:04:32s\n",
      "epoch 127| loss: 0.50289 |  0:04:33s\n",
      "epoch 128| loss: 0.49984 |  0:04:34s\n",
      "epoch 129| loss: 0.4982  |  0:04:34s\n",
      "epoch 130| loss: 0.49105 |  0:04:35s\n",
      "epoch 131| loss: 0.49168 |  0:04:36s\n",
      "epoch 132| loss: 0.49561 |  0:04:37s\n",
      "epoch 133| loss: 0.5015  |  0:04:37s\n",
      "epoch 134| loss: 0.49546 |  0:04:38s\n",
      "epoch 135| loss: 0.49158 |  0:04:39s\n",
      "epoch 136| loss: 0.4932  |  0:04:40s\n",
      "epoch 137| loss: 0.49347 |  0:04:40s\n",
      "epoch 138| loss: 0.49475 |  0:04:41s\n",
      "epoch 139| loss: 0.49553 |  0:04:42s\n",
      "epoch 140| loss: 0.49195 |  0:04:43s\n",
      "epoch 141| loss: 0.48601 |  0:04:43s\n",
      "epoch 142| loss: 0.48616 |  0:04:44s\n",
      "epoch 143| loss: 0.48731 |  0:04:45s\n",
      "epoch 144| loss: 0.49436 |  0:04:46s\n",
      "epoch 145| loss: 0.50353 |  0:04:46s\n",
      "epoch 146| loss: 0.49132 |  0:04:47s\n",
      "epoch 147| loss: 0.48949 |  0:04:48s\n",
      "epoch 148| loss: 0.49138 |  0:04:49s\n",
      "epoch 149| loss: 0.48885 |  0:04:50s\n",
      "epoch 150| loss: 0.48791 |  0:04:50s\n",
      "epoch 151| loss: 0.48669 |  0:04:51s\n",
      "epoch 152| loss: 0.485   |  0:04:52s\n",
      "epoch 153| loss: 0.48088 |  0:04:53s\n",
      "epoch 154| loss: 0.48509 |  0:04:53s\n",
      "epoch 155| loss: 0.48749 |  0:04:54s\n",
      "epoch 156| loss: 0.49724 |  0:04:55s\n",
      "epoch 157| loss: 0.49255 |  0:04:56s\n",
      "epoch 158| loss: 0.50594 |  0:04:56s\n",
      "epoch 159| loss: 0.50971 |  0:04:57s\n",
      "epoch 160| loss: 0.5153  |  0:04:58s\n",
      "epoch 161| loss: 0.5095  |  0:04:59s\n",
      "epoch 162| loss: 0.5054  |  0:04:59s\n",
      "epoch 163| loss: 0.49221 |  0:05:00s\n",
      "epoch 164| loss: 0.49273 |  0:05:01s\n",
      "epoch 165| loss: 0.49316 |  0:05:02s\n",
      "epoch 166| loss: 0.49084 |  0:05:03s\n",
      "epoch 167| loss: 0.48297 |  0:05:04s\n",
      "epoch 168| loss: 0.49134 |  0:05:04s\n",
      "epoch 169| loss: 0.48626 |  0:05:05s\n",
      "epoch 170| loss: 0.48218 |  0:05:06s\n",
      "epoch 171| loss: 0.48705 |  0:05:07s\n",
      "epoch 172| loss: 0.48992 |  0:05:07s\n",
      "epoch 173| loss: 0.49277 |  0:05:08s\n",
      "epoch 174| loss: 0.4799  |  0:05:09s\n",
      "epoch 175| loss: 0.48411 |  0:05:10s\n",
      "epoch 176| loss: 0.50262 |  0:05:11s\n",
      "epoch 177| loss: 0.50113 |  0:05:11s\n",
      "epoch 178| loss: 0.49658 |  0:05:12s\n",
      "epoch 179| loss: 0.49197 |  0:05:13s\n",
      "epoch 180| loss: 0.4956  |  0:05:14s\n",
      "epoch 181| loss: 0.48708 |  0:05:15s\n",
      "epoch 182| loss: 0.49307 |  0:05:15s\n",
      "epoch 183| loss: 0.48617 |  0:05:16s\n",
      "epoch 184| loss: 0.4875  |  0:05:17s\n",
      "epoch 185| loss: 0.48358 |  0:05:18s\n",
      "epoch 186| loss: 0.48034 |  0:05:19s\n",
      "epoch 187| loss: 0.47478 |  0:05:19s\n",
      "epoch 188| loss: 0.46898 |  0:05:20s\n",
      "epoch 189| loss: 0.46984 |  0:05:21s\n",
      "epoch 190| loss: 0.46571 |  0:05:22s\n",
      "epoch 191| loss: 0.46644 |  0:05:23s\n",
      "epoch 192| loss: 0.46756 |  0:05:23s\n",
      "epoch 193| loss: 0.46375 |  0:05:24s\n",
      "epoch 194| loss: 0.46782 |  0:05:25s\n",
      "epoch 195| loss: 0.46696 |  0:05:26s\n",
      "epoch 196| loss: 0.47363 |  0:05:27s\n",
      "epoch 197| loss: 0.47503 |  0:05:28s\n",
      "epoch 198| loss: 0.4688  |  0:05:28s\n",
      "epoch 199| loss: 0.4619  |  0:05:29s\n"
     ]
    }
   ],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import numpy as np\n",
    "\n",
    "# TabNet에 필요한 데이터 준비 (NumPy 형식)\n",
    "X_train_np = np.array(X_train.astype(np.float64).values)\n",
    "X_test_np = np.array(X_test.astype(np.float64).values)\n",
    "y_train_np = np.array(y_train).flatten()\n",
    "y_test_np = np.array(y_test).flatten()\n",
    "\n",
    "# TabNet 모델 정의\n",
    "model = TabNetClassifier()\n",
    "\n",
    "# 학습\n",
    "model.fit(\n",
    "    X_train_np, y_train_np,\n",
    "    max_epochs=200,\n",
    "    patience=5,\n",
    "    batch_size=256,\n",
    "    virtual_batch_size=128\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가\n",
    "y_pred = model.predict(X_test_np)\n",
    "y_pred_proba = model.predict_proba(X_test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6845, np.float64(0.6808321648150145))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "accuracy_score(np.array(y_test).flatten(), y_pred), roc_auc_score(np.array(y_test).flatten(), y_pred_proba[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(np.array(test.astype(np.float64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "today = datetime.today().strftime('%Y-%m-%d')\n",
    "base_filename = f'./data/submission_{today}.csv'\n",
    "filename = base_filename\n",
    "counter = 1\n",
    "\n",
    "while os.path.exists(filename):\n",
    "    filename = f'./data/submission_{today}_{counter}.csv'\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "\n",
    "submit_df = pd.read_csv('./data/sample_submission.csv')\n",
    "submit_df['채무 불이행 확률'] = test_pred\n",
    "submit_df.to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "\n",
    "\n",
    "\n",
    "# AutoML 모델 생성 및 학습\n",
    "automl_model = AutoSklearnClassifier(time_left_for_this_task=60, per_run_time_limit=10)\n",
    "automl_model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 평가\n",
    "print(\"모델 정확도:\", automl_model.score(X_test, y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
